> For a run of ones starting at bit position n down to bit position m (n â‰¥ m),
we saw that we can generate two forms of code, A and B. How should the compiler
decide which form to use?

It should choose cheapest one, computational-wise. For a run of a single one,
it's probably better to use form A. For a run of three of more consecutive
ones, form B is probably the best choice.
